import pandas as pd

#데이터 불러오기
fish = pd.read_csv('http://bit.ly/fish_csv_data')
fish.head()

#Species 열에서 고유한 값 추출하기
print(pd.unique(fish['Species']))

#Species를 타깃으로 나머지는 입력 데이터로 사용
fish_input = fish[['Weight', 'Length', 'Diagonal', 'Height', 'Width']].to_numpy()

#확인
print(fish_input[:5])

#타깃 데이터 생성
fish_target = fish['Species'].to_numpy()

#훈련 세트와 테스트 세트 나누기
from sklearn.model_selection import train_test_split

train_input, test_input, train_target, test_target = train_test_split(fish_input, fish_target, random_state=42)

#표준화 전처리
from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(train_input)
train_scaled = ss.transform(train_input)
test_scaled = ss.transform(test_input)

#훈련(k-최근접 이웃)
from sklearn.neighbors import KNeighborsClassifier

kn = KNeighborsClassifier(n_neighbors=3)
kn.fit(train_scaled, train_target)
print(kn.score(train_scaled, train_target))
print(kn.score(test_scaled, test_target))

#타깃값
print(kn.classes_)

#예측하기
print(kn.predict(test_scaled[:5]))

#확률 출력
import numpy as np

proba = kn.predict_proba(test_scaled[:5])
print(np.round(proba, decimals = 4))

#비율 확인
distances, indexes = kn.kneighbors(test_scaled[3:4])
print(train_target[indexes])

#로지스틱 회귀 이진 분류 (시그모이드 함수 그래프)
import numpy as np
import matplotlib.pyplot as plt

z = np.arange(-5, 5, 0.1)
phi = 1/(1+np.exp(-z))

plt.plot(z, phi)
plt.xlabel('z')
plt.ylabel('phi')
plt.show()

#도미와 빙어만 True
bream_smelt_indexes = (train_target=='Bream') | (train_target=='Smelt')
train_bream_smelt = train_scaled[bream_smelt_indexes]
target_bream_smelt = train_target[bream_smelt_indexes]

#로지스틱 회귀 이진 분류 훈련
from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(train_bream_smelt, target_bream_smelt)

print(lr.predict(train_bream_smelt[:5]))

#확률 출력
print(lr.predict_proba(train_bream_smelt[:5]))

#음성 클래스, 양성 클래스 확인
print(lr.classes_)

#로지스틱 회귀가 학습한 계수
print(lr.coef_, lr.intercept_)

#LogisticRegression으로 z값 계산
decisions = lr.decision_function(train_bream_smelt[:5])
print(decisions)

#시그모이드 함수에 통과시켜 확률 얻기
from scipy.special import expit

print(expit(decisions))

#로지스틱 회귀 (다중 분류)
lr = LogisticRegression(C=20, max_iter=1000)
lr.fit(train_scaled, train_target)

print(lr.score(train_scaled, train_target))
print(lr.score(test_scaled, test_target))

#다중 분류 예측
proba = lr.predict_proba(test_scaled[:5])
print(np.round(proba, decimals=3))

#클래스 정보 확인
print(lr.classes_)

#다중 분류 선형 방정식
print(lr.coef_.shape, lr.intercept_.shape)

#확률 변환
#z값 구하기
decision = lr.decision_function(test_scaled[:5])
print(np.round(decision, decimals = 2))

#소프트맥스 함수
from scipy.special import softmax
proba = softmax(decision, axis=1)
print(np.round(proba, decimals=3))
